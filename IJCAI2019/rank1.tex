%!TEX root = bandit_paper.tex

%We first analyze the simple rank $1$ scenario and propose our solution for this setting. Many of the key aspects of our design principle are captured in this rank-$1$ setting. Note that for $d=1$, $U_t\in [0,1]^{K\times 1}$ is the user preference over a single topic and $V_t \in [0,1]^{L\times 1}$ is the item preference over a single topic. The user-item preference matrix $M_t = U_tV_t^{\intercal}$ is non-negative, non-stochastic, and rank $1$. 


%Also, the hott-topics assumption in eq \eqref{eq:hott topics1} and \eqref{eq:hott topics} still holds in the rank $1$ setting.  In this setting, at every timestep $t\in[n]$ the learner selects a pair of rows and columns, denoted by $i_t$ and $j_t$ respectively and observes the feedback $M_t(i_t,j_t)$.
%
%\todob{Explain why.}
%\todob{Use \textbackslash eqref when referring to equations.}

We present the simple algorithm Low Rank Bandit $\latentranker$ in Algorithm \ref{alg:LRB1} for the rank $1$ setting. The $\latentranker$ consist of two key components, a row learning algorithm and a column learning algorithm. At every round $t$ the row algorithm suggest the row $i_t\in [K]$ and the column algorithm suggests the column $j_t\in [L]$. Note, that in this non-stochastic scenario we use $\expthree$ as the row and column learning algorithm. While the row $\expthree$ consist of $[K]$ arms, the column $\expthree$ consist of $[L]$ arms. The main idea is to use the row $\expthree$ to learn the best row on average while the column $\expthree$ will learn the best column on average. The learner then observes the reward $M_t(i_t, j_t)$ and updates the row and column $\expthree$ simultaneously. A key insight to this simple design is that when both the row and column learner are run simultaneously, they will learn the most rewarding row and column on average and converge on the maximum entry of the the matrix $M$. From the definition of $U_t$, for any sequence of $n$ columns, the maximum value is in row $i^\ast$. This means that the row algorithm learns oblivious to what the column algorithm does. From the definition of $V_t$, for any sequence of $n$ rows, the maximum value is in column $j^\ast$. This means that the column algorithm learns oblivious of what the row algorithm does.

%\todob{Use ``round'' instead of time, timestep, step, and such.}

%\todob{We need to clearly explain what is going on here. From the definition of $U_t$, for any sequence of $n$ columns, the maximum value is in row $i^\ast$. This means that the row algorithm learns no matter what the column algorithm does. From the definition of $V_t$, for any sequence of $n$ rows, the maximum value is in column $j^\ast$. This means that the column algorithm learns no matter what the row algorithm does.}

\begin{algorithm}[t]
  \caption{Low Rank Bandit ($\latentranker$) (Rank 1)}
  \label{alg:LRB}
  \begin{algorithmic}[1]
    \State \textbf{Input:} Time horizon $n$
    \Comment{Initialization}
      \State Initialize $\rowalg $
      \State Initialize $\colalg $
    \For{$t = 1, \dots, n$}
      \Comment{Generate response}
        \State Row $i_t$ suggested by $\rowalg$
        \State Column $j_t$ suggested by $\colalg$
        \State Observe $M_t(i_t, j_t)$
      \Comment{Update statistics}
    \State Update arm $i_t$ of $\rowalg$ with reward $M_t(i_t, j_t)$.
    \State Update arm $j_t$ of $\colalg$ with reward $M_t(i_t, j_t)$.
     \EndFor
  \end{algorithmic}
\end{algorithm}
