In this paper, we studied the problem of finding the highest entry of a non-stochastic, non-negative low-rank matrix. We formulated the above problem as an online-learning problem and proposed the $\latentranker$ algorithm for this setting. We proved that an instance of algorithm has a regret bound in the special case of rank-$1$ setting that scales as $O\left(\frac{\left(\sqrt{L } + \sqrt{K }\right) \sqrt{n}}{\alpha}\right)$ and has the correct order with respect to users, items and rank of the user-item preference matrix $M$. We also evaluated our proposed algorithm on several simulated and real-life datasets and show that it outperforms the existing state-of-the-art algorithms. There are several directions where this work can be extended. Note, that we only proved our theoretical results for the rank $1$ setting. Proving theoretical guarantees for $\latentranker$ algorithm will require additional assumptions on the structure of rewards and the matrix $M$. Another interesting direction is to look at structures beyond hott-topics assumption on user and item matrix.

%There are several directions where this work can be extended. Note, that observing $d$ items at every timestep is helping LRA to learn more efficiently. Hence,  while keeping the hott-topics assumption it is worthwhile to study the personalized ranking setting when only $1$ item is allowed to be suggested at every timestep $t$. Another interesting direction is to look at structures where there are hott-topics assumption on user matrix as well as item matrix or maybe even at structures beyond hott-topics.
