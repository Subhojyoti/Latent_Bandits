In this paper, we study the problem of recommending the best items to users who are coming sequentially. The learner has access to very less prior information about the users (cold start) and it has to adapt quickly to the user preferences and suggest the best item to each user. We assume that the user-item preferences depends on latent factors. The learner only has access to noisy observations from the user-item preference matrix and the latent user or item features are not accessible. We further assume that the user-item preference matrix has low-rank, which is a very common assumption in recommender systems \citep{koren2009matrix}, \citep{ricci2011liorrokach}. %Also, we assume that each user has a single highest item.

	This complex problem can be conceptualized as a low rank online learning  problem where there are $K$ users and $L$ items. The user-item preference  matrix, denoted by $M\in [0,1]^{K\times L}$,  generating the feedback for user, item interaction has a low rank structure. The online learning game proceeds as follows, at every timestep $t$,  nature reveals one user (or row index) \todoan{nature doesn't reveal the row, you can say row index} \todosb{changed it to index} from $M$ where user is denoted by $i_t$. The learner selects $d$ items (or columns) from $[L]$, where an item is denoted by $\ell _{j, t}\in [L]$. Let this $d$ items denoted by $\lbrace \ell_{1}, \ell_2, \dots, \ell_d$ and belong to the set $S_t$ . The learner then receives feedback $r_{t}(i_t,\ell_{j,t})$ for all the $d$ items in $S_t$ from a noisy realization of $M$. This noisy realization of $M$ at time $t$ is denoted by $\tilde{M}_t$ and  $r_{t}(i_t,\ell_{j,t})] \sim \tilde{M}_t(i_t,\ell_{j,t})$. Then the goal of the learner is to minimize the cumulative regret, that is to minimize the total number of wrong items displayed over time to the user at rank position $1$. Hence, the learner needs to quickly identify the best item $\ell_{j^*}$ for each $i\in [K]$ where $M(i,\ell_{j^*}) = \argmax _{j\in[L]} M(i,j)$ and show it in rank position $1$. 
	
	\todoan{This doesn't completely explain our model where the permutation matters} 
	\todosb{I changed it now to say about how we need the best item at rank position 1}

	This learning model is motivated from the real-world scenario where the learner has  to suggest movies to users and each movie belongs to a different genre (say thriller, romance, comedy, etc). So, the learner can suggest $d$ movies belonging to different genres to each incoming user on a webpage, and the user can click one, or all, or none of the recommended movies. \todoan{You can probably remove query abandonment comment.}	
	
\todosb{removed query abandonment comment}
	
% where $Ber$ is a Binomial distribution over the entries in $M$