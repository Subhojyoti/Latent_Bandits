\def\year{2019}\relax
%File: formatting-instruction.tex
\documentclass[letterpaper]{article} %DO NOT CHANGE THIS
\usepackage{aaai19}  %Required
\usepackage{times}  %Required
\usepackage{helvet}  %Required
\usepackage{courier}  %Required
\usepackage{url}  %Required
\usepackage{graphicx}  %Required


%%%%%%%%%%%%% ADD CUSTOM PACKAGES TO macros.sty
\usepackage{macros}

%%%%%%%%%%%%%For adding comments

\newcommand{\todob}[2][]{\todo[color=cyan!20,size=\tiny,inline,#1]{B: #2}} % Brano's comments
\newcommand{\todosb}[2][]{\todo[color=green!20,size=\tiny,inline, #1]{S: #2}} %
\newcommand{\todoan}[2][]{\todo[color=black!20,size=\tiny,inline, #1]{A: #2}} %

\frenchspacing  %Required
\setlength{\pdfpagewidth}{8.5in}  %Required
\setlength{\pdfpageheight}{11in}  %Required
%PDF Info Is Required:
  \pdfinfo{
/Title (2019 Formatting Instructions for Authors Using LaTeX)
/Author (AAAI Press Staff)}
\setcounter{secnumdepth}{2}  
 \begin{document}
% The file aaai.sty is the style file for AAAI Press 
% proceedings, working notes, and technical reports.
%
\title{Latent Ranked Bandit}
\author{Author names withheld}
%\author{AAAI Press\\
%Association for the Advancement of Artificial Intelligence\\
%2275 East Bayshore Road, Suite 160\\
%Palo Alto, California 94303\\
%}
\maketitle
\begin{abstract}
We study the problem of learning personalized ranked lists of diverse items for multiple users, from sequential observations of user preferences. The user-item preference matrix is non-negative and low-rank. Existing methods for solving similar problems are based on reconstructing the preference matrix from its noisy observations using matrix factorization techniques, and typically require strong assumptions on the reconstructed matrix. We depart from this standard approach and focus on a family of low-rank matrices, where the set of most preferred items of all users is small and can be learned efficiently. Then we learn to present this set to each user in a personalized manner, in the order of the descending preferences of the user. We propose a computationally-efficient algorithm that implements this procedure, which we call latent ranker (LR), and prove a sublinear bound on its $n$-step regret. We evaluate the algorithm empirically on several synthetic and real-world datasets. In all experiments, we outperform existing state-of-the-art algorithms.
\end{abstract}

\section{Introduction}
\label{intro}
\input{intro}
\subsection{Contributions}
\label{Contribution}
\input{Contributions}


\section{Setting}
\label{sec:setting}
\input{setting}

%\todob{Why would you write contributions here? Contributions need to be clearly stated in Introduction.}

%\newpage
\section{Algorithm}
\label{sec:algorithm}
\input{Algorithm}

\section{Analysis}
\label{analysis}
\input{analysis}

%\newpage
\section{Experiments}
\label{expt}
\input{expt}

\section{Related Work}
\label{related}
\input{related}

\section{Conclusions and Future Directions}
\label{conclusions}
\input{conclusions}



\newpage
\bibliographystyle{aaai}
\bibliography{biblio}


\appendix
\input{appendix}

\end{document}
