Our work lies at the intersection of several existing areas of research, which we survey below. 
\todoan{This can be compressed a lot. For one, if a there are just 1-2 papers using something, that shouldn't be part of a classification. This is the case, for example, when you say literature for latent bandits can be classified. You are describing things in too much detail. You can just say the setting which the other papers deal and why they they are different than this paper etc}

\textbf{Latent Bandits:} The existing algorithms in latent bandit literature can be broadly classified into two groups: the online matrix completion algorithms and the independent user model algorithms. The \textit{online matrix completion algorithms} try to reconstruct the user-item preference matrix $M$ from a noisy realization combining different approaches of online learning algorithms and matrix factorization algorithms. 
The NMF-Bandit algorithm in \citet{sen2016contextual} is an online matrix completion algorithm which is an $\epsilon$-greedy algorithm that tries to reconstruct the matrix $M$ through non-negative matrix factorization. Note, that this approach requires that all the matrices satisfy a weak statistical Restricted Isometric Property, which is not always feasible in real life applications. Another approach is that of \citet{gopalan2016low} where the authors come up with an algorithm which uses the Robust Tensor Power (RTP) method of 
\citet{anandkumar2014tensor} to reconstruct the matrix $M$, and then use the OFUL procedure of \citet{abbasi2011improved} to behave greedily over the reconstructed matrix. 
But the RTP is a costly operation because the learner needs to construct a matrix of order $L\times L$ and $L\times L \times L$ to calculate the second and third order tensors for the reconstruction.  A more simpler setting has also been studied in \citet{maillard2014latent} where all the users tend to come from only one class and hence this approach is also not quite realistic. 

The second type of algorithms are the \textit{independent user model algorithms} where for each user $i\in[K]$ a separate instance of a base-bandit algorithm is implemented to find the best item for the user. These base -bandits run independent of each other without sharing any information. These can be randomized algorithms suited for the adversarial setting like EXP3 \citep{auer2002nonstochastic} or UCB type algorithms suited for the stochastic setting llike UCB1 \citep{auer2002finite}, MOSS \citep{audibert2009minimax}, OCUCB \citep{lattimore2015optimally}, KL-UCB \citep{cappe2013kullback}, \citep{garivier2011kl} or even Bayesian algorithms like Thompson Sampling \citep{thompson1933likelihood}, \citep{thompson1935theory}, \citep{agrawal2012analysis}.

%can be used for this purpose.
%which are a set of frequentist indexed based algorithms
% Several powerful variation of the stochastic or non-stochastic multi-armed bandit algorithms can be used for this purpose.
%method with $\epsilon$ probability or with $1-\epsilon$ it behaves greedily over the already reconstructed matrix $\hat{M}$.

\textbf{Ranked Bandits:} Bandits have been used to rank items for online recommendations where the goal is is to present a list of $d$ items out of $L$ that maximizes the satisfaction of the user. A popular approach is to model each of the $d$ rank positions as a Multi Armed Bandit (MAB) problem and use a base-bandit algorithm to solve it. This was first proposed in \citet{radlinski2008learning} which  showed that query abandonment by user can also be successfully used to learn rankings. Later works on ranking such as \citet{slivkins2010ranked} and \citet{slivkins2013ranked} uses additional assumptions to handle  exponentially large number of items such that items and user models lie within a metric space and satisfy Lipschitz condition. 

\textbf{Ranking in Click Models:} Several algorithms have been proposed to solve the ranking problem in specific click models. Popular click models that have been studied extensively are Document Click Model (DCM), Position Based Click Model (PBM) and Cascade Click Model (CBM). For a survey of existing click models a reader may look into \citet{chuklin2015click}. While \citet{katariya2017bernoulli}, \citet{katariya2016stochastic} works in PBM, \citet{zoghi2017online} works in both PBM and CBM. Finally, \citet{kveton2017stochastic} can be viewed as a generalization of rank-1 bandits of \citet{katariya2016stochastic} to a higher rank. Note, that the theoretical guarantees of these algorithms does not hold beyond the specific click models.


\textbf{Online Sub-modular maximization:} Maximization of submodular functions has wide applications in machine learning, artificial
intelligence and in recommender systems \citep{nemhauser1978analysis}, \citep{krause2014submodular}. A submodular function $f : 2^V \rightarrow \mathbb{R}$ for a finite ground set $V$ is a set function that assign each
subset $S \subseteq V$ a value $f(S)$. We define the gain of the function $f$ as $G_f(e|S) = f(S \cup \lbrace e\rbrace) - f(S)$ where the element $\lbrace e\rbrace \in V\setminus S$ and $S \subseteq V$. Also, $f$ satisfies the following two criteria:-
\begin{enumerate}
\item Monotonicity: A set function $f : 2^V \rightarrow \mathbb{R}$ is monotone if for every $A \subseteq B \subseteq V, f(A) \leq f(B)$.
\item Submodularity: A set function $f : 2^V \rightarrow \mathbb{R}$ is submodular if for every $A \subseteq B \subseteq V$ and $\lbrace e\rbrace \in V \setminus B$ it holds that $G_f(e | A) \geq G_f(e | B)$.
\end{enumerate}

Intuitively, a submodular function states that after performing a set $A$ of actions, the marginal gain of another action $e$ does not increase the gain for performing other actions in $B \setminus A$. Online submodular function maximization has been studied in \citet{streeter2009online} where the authors propose a general algorithm whereas  \citet{radlinski2008learning} can be considered as special case of it when the payoff is only between $\lbrace 0, 1\rbrace$. Also, in the contextual feature based setup online  submodular maximization has been studied by  \citet{yue2011linear}. An interesting property of submodular function is that a greedy algorithm using it is guaranteed to perform atleast $\left( 1 - \frac{1}{e}\right)$ of the optimal algorithm and this factor $\left( 1 - \frac{1}{e}\right)$ is not improvable by any polynomial time algorithm \citep{nemhauser1978analysis}.


