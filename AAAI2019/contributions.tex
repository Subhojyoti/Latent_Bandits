Our contributions are mainly three fold. First, we formulate the latent ranked bandit problem as an online learning problem on a class of low-rank non-negative matrices that can be solved efficiently without estimating the latent factors that generate the matrices. We borrow ideas from the ranking literature to solve this problem efficiently and term this setting as personalized ranking setting. This is because an efficient algorithm can find a global ranking of best items and then permute that list to find a personalized ranking for individual users, sorted in descending order of their preference towards item. Secondly, we propose the latent ranker algorithm (LRA) for this personalized ranking setting. LRA has two components, the column algorithms that suggests $d$ columns and the row ranking component which permutes that suggested list to find the best permutation amongst them. The best permutation is personalized for each user such that it will contain the best item for that user at rank $1$ position with high probability. The column algorithms leverage the low rank structure of the user-preference matrix $M$ and quickly finds out the $d$ best items. Simultaneously the row ranking components observe all the feedback from the user permute the suggested list of $d$ items to find the highest reward permutation such that the best item is at rank $1$ position for the individual users. Finally, we show that an instance of LRA which uses exponential weighting algorithm EXP3 as column MABs and weighted majority algorithm (WMA) as row MABs suffer a regret of atmost $O\left(d^2\sqrt{L n} + K \log n\right)$. On diverse experimental settings we test our proposed algorithm and show improved performance even when our modeling assumptions does not hold.

	The rest of the paper is organized as follows. We state our setting, assumptions and notations in Section \ref{sec:setting}. We propose the algorithm LRA in Section \ref{sec:algorithm} and in Section \ref{sec:analysis} we analyze LRA. Finally, we show experiments in Section \ref{sec:expt} and give a brief survey of the existing literature in Section \ref{sec:related}. We conclude in Section \ref{sec:conclusions} while the proof is contained in the Appendix \ref{sec:proof}.