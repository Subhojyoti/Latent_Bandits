%!TEX root = paper.tex

In this work, we study the problem of learning personalized ranked lists of diverse items for multiple users, from sequential observations of user preferences. We are interested in utilizing latent similarities among users and items to learn these lists much faster than learning a separate ranked list for each user. The key structure in our problem is that the user-item preference matrix is low rank, which is a standard assumption in recommender systems \citep{koren2009matrix,ricci2011liorrokach}. The learning agent has access to noisy observations of the user-item matrix. It does not have access to either user or item latent factors.

We formalize our learning problem as the following online learning problem. At time $t$, a random user $i_t$ arrives to the recommender system. The learning agent observes the identity of the user, recommends a list of $d$ diverse items $J_t$ as a response, observes the preferences of the user for all recommended items. The user-item preference matrix is assumed to be low-rank at each time $t$, and can vary substantially over time. The reward of the list is high when highly preferred items are recommended at higher positions. The goal of our learning agent is to compete with the most rewarding diverse list for each user in hindsight.

Our learning model is motivated by a real-world scenario, where the learning agent suggests movies to users and each movie belongs to different movie genres. The agent typically does not observe instantaneous preferences of the user, and therefore suggests multiple movies that may be of interest to the user under different circumstances. \todob{This is actually the main motivation for diversity. We needs to add references and discuss this in detail.}
