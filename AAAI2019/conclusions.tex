In this paper, we studied the problem of suggesting a diverse list of items to users, with the best item of individual users at rank position $1$. We formulated the above problem as a personalized ranking problem and proposed the Latent Ranked Bandit algorithm for this setting. We proved that an instance of algorithm has  a regret bound that scales as $O\left(d^2\sqrt{L n} + K \log n\right)$ and has the correct order with respect to user, items and rank of the user-item preference matrix $M$. We also evaluated our proposed algorithm on several simulated and real-life datasets and show that it outperforms the existing state-of-the-art algorithms.

There are several future directions where this work can be extended. Note, that observing $d$ items at every timestep is helping LRA to learn more efficiently. Hence,  while keeping the hott-topics assumption it is worthwhile to study the personalized ranking setting when only $1$ item is allowed to be suggested at every timestep $t$. Another interesting direction is to look at structures where there are hott-topics assumption on user matrix as well as item matrix or maybe even at structures beyond hott-topics.


%todosb{suggest some future directions}