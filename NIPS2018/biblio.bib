@article{maillard2014latent,
  title={Latent Bandits.},
  author={Maillard, Odalric-Ambrym and Mannor, Shie},
  year={2014}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={1998},
  publisher={MIT press}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo},
  journal={arXiv preprint arXiv:1204.5721},
  year={2012}
}

@article{agrawal2011analysis,
  title={Analysis of thompson sampling for the multi-armed bandit problem},
  author={Agrawal, Shipra and Goyal, Navin},
  journal={arXiv preprint arXiv:1111.1797},
  year={2011}
}

@article{bubeck2012bandits,
  title={Bandits with heavy tail},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  journal={arXiv preprint arXiv:1209.1727},
  year={2012}
}

@article{bubeck2013bounded,
  title={Bounded regret in stochastic multi-armed bandits},
  author={Bubeck, S{\'e}bastien and Perchet, Vianney and Rigollet, Philippe},
  journal={arXiv preprint arXiv:1302.1611},
  year={2013}
}

@article{perchet2015batched,
  title={Batched Bandit Problems},
  author={Perchet, Vianney and Rigollet, Philippe and Chassang, Sylvain and Snowberg, Erik},
  journal={arXiv preprint arXiv:1505.00369},
  year={2015}
}

@inproceedings{audibert2010best,
  title={Best arm identification in multi-armed bandits},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien},
  booktitle={COLT-23th Conference on Learning Theory-2010},
  pages={13--p},
  year={2010}
}

@article{garivier2011kl,
  title={The KL-UCB algorithm for bounded stochastic bandits and beyond},
  author={Garivier, Aur{\'e}lien and Capp{\'e}, Olivier},
  journal={arXiv preprint arXiv:1102.2490},
  year={2011}
}

@inproceedings{audibert2009minimax,
  title={Minimax policies for adversarial and stochastic bandits},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien},
  booktitle={COLT},
  pages={217--226},
  year={2009}
}

@inproceedings{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2312--2320},
  year={2011}
}

@article{even2006action,
  title={Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems},
  author={Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay},
  journal={The Journal of Machine Learning Research},
  volume={7},
  pages={1079--1105},
  year={2006},
  publisher={JMLR. org}
}

@article{audibert2009exploration,
  title={Exploration--exploitation tradeoff using variance estimates in multi-armed bandits},
  author={Audibert, Jean-Yves and Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Theoretical Computer Science},
  volume={410},
  number={19},
  pages={1876--1902},
  year={2009},
  publisher={Elsevier}
}

@article{auer2010ucb,
  title={UCB revisited: Improved regret bounds for the stochastic multi-armed bandit problem},
  author={Auer, Peter and Ortner, Ronald},
  journal={Periodica Mathematica Hungarica},
  volume={61},
  number={1-2},
  pages={55--65},
  year={2010},
  publisher={Springer}
}

@article{auer2002finite,
  title={Finite-time analysis of the multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  journal={Machine learning},
  volume={47},
  number={2-3},
  pages={235--256},
  year={2002},
  publisher={Springer}
}

@incollection{robbins1952some,
  title={Some aspects of the sequential design of experiments},
  author={Robbins, Herbert},
  booktitle={Herbert Robbins Selected Papers},
  pages={169--177},
  year={1952},
  publisher={Springer}
}

@article{lai1985asymptotically,
  title={Asymptotically efficient adaptive allocation rules},
  author={Lai, Tze Leung and Robbins, Herbert},
  journal={Advances in applied mathematics},
  volume={6},
  number={1},
  pages={4--22},
  year={1985},
  publisher={Elsevier}
}

@article{thompson1933likelihood,
  title={On the likelihood that one unknown probability exceeds another in view of the evidence of two samples},
  author={Thompson, William R},
  journal={Biometrika},
  pages={285--294},
  year={1933},
  publisher={JSTOR}
}

@book{friedman2001elements,
  title={The elements of statistical learning},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  volume={1},
  year={2001},
  publisher={Springer series in statistics Springer, Berlin}
}

@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM Journal on Computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}

@misc{CapGarKau12,
 author={Olivier Cappe and Aurelien Garivier and Emilie Kaufmann},
 title={pymaBandits},
 year={2012},
 note={\url{http://mloss.org/software/view/415/}}
}

@inproceedings{honda2010asymptotically,
  title={An Asymptotically Optimal Bandit Algorithm for Bounded Support Models.},
  author={Honda, Junya and Takemura, Akimichi},
  booktitle={COLT},
  pages={67--79},
  year={2010},
  organization={Citeseer}
}

@article{lattimore2015optimally,
  title={Optimally confident UCB: Improved regret for finite-armed bandits},
  author={Lattimore, Tor},
  journal={arXiv preprint arXiv:1507.07880},
  year={2015}
}

@article{liu2016modification,
  title={Modification of improved upper confidence bounds for regulating exploration in Monte-Carlo tree search},
  author={Liu, Yun-Ching and Tsuruoka, Yoshimasa},
  journal={Theoretical Computer Science},
  year={2016},
  publisher={Elsevier}
}

@article{mannor2004sample,
  title={The sample complexity of exploration in the multi-armed bandit problem},
  author={Mannor, Shie and Tsitsiklis, John N},
  journal={Journal of Machine Learning Research},
  volume={5},
  number={Jun},
  pages={623--648},
  year={2004}
}

@article{mellor2013thompson,
  title={Thompson sampling in switching environments with bayesian online change point detection},
  author={Mellor, Joseph and Shapiro, Jonathan},
  journal={CoRR, abs/1302.3721},
  year={2013}
}

@inproceedings{agrawal2012analysis,
  title={Analysis of Thompson Sampling for the Multi-armed Bandit Problem.},
  author={Agrawal, Shipra and Goyal, Navin},
  booktitle={COLT},
  pages={39--1},
  year={2012}
}

@inproceedings{agrawal2013further,
  title={Further Optimal Regret Bounds for Thompson Sampling.},
  author={Agrawal, Shipra and Goyal, Navin},
  booktitle={Aistats},
  pages={99--107},
  year={2013}
}

@inproceedings{garivier2011upper,
  title={On upper-confidence bound policies for switching bandit problems},
  author={Garivier, Aur{\'e}lien and Moulines, Eric},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={174--188},
  year={2011},
  organization={Springer}
}

